{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 1,
=======
   "execution_count": 18,
>>>>>>> Stashed changes
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Get URL and Save It As a .csv File\n",
    "\n",
    "# url_share\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, re, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# URL Crawler\n",
    "url_share = 'https://rent.591.com.tw/home/rent/index/r1s7k3.html?kind=1&region=1&section=7,7'\n",
    "html_share = requests.get(url_share).text\n",
    "sp = BeautifulSoup(html_share, 'html.parser')\n",
    "\n",
    "links_share = []\n",
    "for a in sp.find_all('a', href=True):\n",
    "    if '/rent-detail' in a['href']:\n",
    "        links_share_modified = \"https:\" + a['href']\n",
    "        links_share_clean1 = links_share_modified.replace(\" \", \"\")\n",
    "        links_share_clean2 = links_share_clean1.replace(\"\\n\", \"\")\n",
    "        links_share.append(links_share_clean2)\n",
    "print(links_share)\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# Output\n",
    "#df_share = pd.DataFrame(links_share, columns=['URL'])\n",
    "#df_share.to_csv('df_share.csv')\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# Memo\n",
    "#url_share     = 'https://rent.591.com.tw/home/rent/index/r1s7k3.html?kind=1&region=1&section=7,7'\n",
    "#url_studioInd = 'https://rent.591.com.tw/home/rent/index/r1s7k3.html?kind=2&region=1&section=7,7'\n",
    "#url_studioSep = 'https://rent.591.com.tw/home/rent/index/r1s7k3.html?kind=3&region=1&section=7,7'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# url_studioInd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, re, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# URL Crawler\n",
    "url_studioInd = 'https://rent.591.com.tw/home/rent/index/r1s7k3.html?kind=2&region=1&section=7'\n",
    "html_studioInd = requests.get(url_studioInd).text\n",
    "sp = BeautifulSoup(html_studioInd, 'html.parser')\n",
    "\n",
    "links_studioInd = []\n",
    "for a in sp.find_all('a', href=True):\n",
    "    if '/rent-detail' in a['href']:\n",
    "        links_studioInd_modified = \"https:\" + a['href']\n",
    "        links_studioInd_clean1 = links_studioInd_modified.replace(\" \", \"\")\n",
    "        links_studioInd_clean2 = links_studioInd_clean1.replace(\"\\n\", \"\")\n",
    "        links_studioInd.append(links_studioInd_clean2)\n",
    "print(links_studioInd)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# Output\n",
    "#df_studioInd = pd.DataFrame(links_studioInd, columns=['URL'])\n",
    "#df_studioInd.to_csv('df_studioInd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# url_studioSep\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, re, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# URL Crawler\n",
    "url_studioSep = 'https://rent.591.com.tw/home/rent/index/r1s7k3.html?kind=3&region=1&section=7'\n",
    "html_studioSep = requests.get(url_studioSep).text\n",
    "sp = BeautifulSoup(html_studioSep, 'html.parser')\n",
    "\n",
    "links_studioSep = []\n",
    "for a in sp.find_all('a', href=True):\n",
    "    if '/rent-detail' in a['href']:\n",
    "        links_studioSep_modified = \"https:\" + a['href']\n",
    "        links_studioSep_clean1 = links_studioSep_modified.replace(\" \", \"\")\n",
    "        links_studioSep_clean2 = links_studioSep_clean1.replace(\"\\n\", \"\")\n",
    "        links_studioSep.append(links_studioSep_clean2)\n",
    "print(links_studioSep)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# Output\n",
    "df_studioSep = pd.DataFrame(links_studioSep, columns=['URL'])\n",
    "df_studioSep.to_csv('df_studioSep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the .csv file\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, re, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_share = pd.read_csv('df_share.csv')\n",
    "data_studioInd = pd.read_csv('df_studioInd.csv')\n",
    "data_studioSep = pd.read_csv('df_studioSep.csv')\n",
    "#print(data_share)\n",
    "#data_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 2: Read Separate House Info\n",
    "\n",
    "# Read the .csv file\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, re, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_share = pd.read_csv('df_share.csv')\n",
    "data_studioInd = pd.read_csv('df_studioInd.csv')\n",
    "data_studioSep = pd.read_csv('df_studioSep.csv')\n",
    "#data_share\n",
    "\n",
    "# Place\n",
    "urls_share_URL = data_share.URL\n",
    "place = []\n",
    "for url_share in urls_share_URL:\n",
    "    html_share = requests.get(url_share).text\n",
    "    sp = BeautifulSoup(html_share, 'html.parser')\n",
    "    for div in sp.find_all('div[class=\"lifeBox\"]'):\n",
    "        place.append(div)    \n",
    "    print (place)\n",
    "\n",
    "#urls_studioInd = csv.reader(open('df_studioInd.csv'))\n",
    "#for url_studioInd in urls_studioInd:\n",
    "#    response = urllib2.urlopen(url_studioInd[0])\n",
    "#    html = response.read()\n",
    "#    print re.findall('p',html)\n",
    "\n",
    "#urls_studioSep = csv.reader(open('df_studioSep.csv'))\n",
    "#for url_studioSep in urls_studioSep:\n",
    "#    response = urllib2.urlopen(url_studioSep[0])\n",
    "#    html = response.read()\n",
    "#    print re.findall('p',html)\n",
    "\n",
    "\n",
    "# Price\n",
    "\n",
    "# Addtional Service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
